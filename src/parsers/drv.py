"""Parser for OpenROAD Design Rule Violation (DRV/DRC) reports."""

import re
from pathlib import Path

from src.controller.types import DRVMetrics


def parse_drv_report(report_content: str) -> DRVMetrics:
    """
    Parse OpenROAD DRC/DRV report.

    The report is typically generated by detailed routing checks.
    Expected formats vary, but common patterns include:

        Total violations: 123
        Spacing violations: 45
        Width violations: 30
        Short violations: 20
        ...

    Or OpenROAD's check_drc output:

        Violation: Metal2 spacing violation at (x, y)
        Violation: Metal3 min-width violation at (x, y)
        ...
        Total DRC violations: 85

    Args:
        report_content: Content of DRC report file

    Returns:
        DRVMetrics with violation counts

    Raises:
        ValueError: If report cannot be parsed
    """
    lines = report_content.strip().split("\n")

    total_violations: int | None = None
    violation_types: dict[str, int] = {}
    critical_violations: int | None = None
    warning_violations: int | None = None

    # Count violations by parsing individual violation lines
    violation_count_from_lines = 0

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # Parse total violations (check first)
        # Matches: "Total violations: 123" or "Total DRC violations = 123"
        if match := re.search(
            r"total\s+(?:DRC\s+)?violations?[:\s=]+(\d+)", line, re.IGNORECASE
        ):
            total_violations = int(match.group(1))

        # Parse critical violations (check before generic types)
        # Matches: "Critical violations: 10" or "Blocking violations = 5"
        elif match := re.search(
            r"(?:critical|blocking)\s+violations?[:\s=]+(\d+)", line, re.IGNORECASE
        ):
            critical_violations = int(match.group(1))

        # Parse warning violations (check before generic types)
        # Matches: "Warning violations: 20" or "Non-critical = 15"
        elif match := re.search(
            r"(?:warning|non-critical)\s+violations?[:\s=]+(\d+)", line, re.IGNORECASE
        ):
            warning_violations = int(match.group(1))

        # Parse violation type counts (generic, must come after specific types)
        # Matches: "Spacing violations: 45" or "Metal2 spacing = 30"
        elif match := re.search(
            r"(\w+(?:\s+\w+)?)\s+violations?[:\s=]+(\d+)", line, re.IGNORECASE
        ):
            viol_type = match.group(1).lower().strip()
            count = int(match.group(2))

            # Accumulate by type
            if viol_type in violation_types:
                violation_types[viol_type] += count
            else:
                violation_types[viol_type] = count

        # Count individual violation reports
        # Matches: "Violation: ..." or "DRC violation at ..."
        elif re.search(r"\bviolation\b[:\s]", line, re.IGNORECASE):
            violation_count_from_lines += 1

            # Try to extract violation type from the line
            # Common patterns: "Metal2 spacing violation", "min-width violation"
            if type_match := re.search(
                r"(spacing|width|short|enclosure|area|min-width|min-area)\s+violation",
                line,
                re.IGNORECASE,
            ):
                viol_type = type_match.group(1).lower()
                violation_types[viol_type] = violation_types.get(viol_type, 0) + 1

    # If total not explicitly stated, use count from parsing individual lines
    if total_violations is None:
        if violation_count_from_lines > 0:
            total_violations = violation_count_from_lines
        elif sum(violation_types.values()) > 0:
            total_violations = sum(violation_types.values())
        else:
            # No violations found - report is clean
            total_violations = 0

    return DRVMetrics(
        total_violations=total_violations,
        violation_types=violation_types,
        critical_violations=critical_violations,
        warning_violations=warning_violations,
    )


def parse_drv_report_file(file_path: str) -> DRVMetrics:
    """
    Parse DRC report from file.

    Args:
        file_path: Path to DRC report file

    Returns:
        DRVMetrics

    Raises:
        FileNotFoundError: If file doesn't exist
        ValueError: If report cannot be parsed
    """
    path = Path(file_path)
    if not path.exists():
        raise FileNotFoundError(f"DRC report not found: {file_path}")

    content = path.read_text()
    return parse_drv_report(content)


def format_drv_summary(metrics: DRVMetrics) -> str:
    """
    Format DRV metrics as human-readable summary.

    Args:
        metrics: DRVMetrics to format

    Returns:
        Human-readable summary string
    """
    lines = []
    lines.append(f"Total DRC violations: {metrics.total_violations}")

    if metrics.critical_violations is not None:
        lines.append(f"Critical violations: {metrics.critical_violations}")

    if metrics.warning_violations is not None:
        lines.append(f"Warning violations: {metrics.warning_violations}")

    if metrics.violation_types:
        lines.append("\nViolations by type:")
        for viol_type, count in sorted(
            metrics.violation_types.items(), key=lambda x: x[1], reverse=True
        ):
            lines.append(f"  {viol_type}: {count}")

    return "\n".join(lines)


def is_drv_clean(metrics: DRVMetrics, allow_warnings: bool = True) -> bool:
    """
    Check if design is DRC-clean.

    Args:
        metrics: DRVMetrics to check
        allow_warnings: If True, only critical violations count as failures

    Returns:
        True if design passes DRC checks
    """
    if allow_warnings:
        # Only critical violations are failures
        if metrics.critical_violations is not None:
            return metrics.critical_violations == 0
        # If no critical/warning distinction, check total
        return metrics.total_violations == 0
    else:
        # All violations count
        return metrics.total_violations == 0
